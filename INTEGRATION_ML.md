# üî¨ Guide d'Int√©gration ML R√©el - M.A.D.E

## ‚úÖ Ce qui a √©t√© impl√©ment√©

1. **Service ML Backend** (`backend/services/ml_service.js`)
   - Structure pr√™te pour int√©grer un mod√®le ML r√©el
   - Preprocessing d'images
   - Support pour paludisme, typho√Øde et analyse mixte

2. **API ML** (`backend/routes/ml_analysis.js`)
   - Endpoint `/api/ml/analyze` pour l'analyse d'images
   - Endpoint `/api/ml/health` pour v√©rifier l'√©tat du service

3. **Int√©gration Flutter**
   - Appel API ML depuis l'application Flutter
   - Pas de simulation, utilise le backend ML r√©el

4. **Authentification am√©lior√©e**
   - Bcrypt pour le hashage des mots de passe
   - JWT pour l'authentification s√©curis√©e

## üöÄ √âtapes pour int√©grer un vrai mod√®le ML

### Option 1 : TensorFlow.js (Recommand√© pour Node.js)

1. **Installer TensorFlow.js**
```bash
cd backend
npm install @tensorflow/tfjs-node
```

2. **Entra√Æner ou obtenir un mod√®le**
   - Entra√Æner un mod√®le avec TensorFlow/Keras
   - Convertir en format TensorFlow.js
   - Placer le mod√®le dans `backend/models/`

3. **Modifier `ml_service.js`**
```javascript
const tf = require('@tensorflow/tfjs-node');
const path = require('path');
const fs = require('fs');

class MLService {
  constructor() {
    this.model = null;
    this.modelLoaded = false;
  }

  async loadModel() {
    try {
      const modelPath = path.join(__dirname, '../models/malaria_model.json');
      if (fs.existsSync(modelPath)) {
        this.model = await tf.loadLayersModel(`file://${modelPath}`);
        this.modelLoaded = true;
        console.log('‚úÖ Mod√®le TensorFlow charg√© avec succ√®s');
      }
    } catch (error) {
      console.error('‚ùå Erreur lors du chargement du mod√®le:', error);
    }
  }

  async analyzeMalaria(imageBuffer) {
    if (!this.model) {
      throw new Error('Mod√®le non charg√©');
    }

    // Preprocesser l'image pour le mod√®le
    const preprocessed = this.preprocessForModel(imageBuffer);
    
    // Faire la pr√©diction
    const prediction = this.model.predict(preprocessed);
    const result = await prediction.data();
    
    // Interpr√©ter les r√©sultats
    return this.interpretResults(result);
  }
}
```

### Option 2 : Service Python s√©par√© (Recommand√© pour production)

1. **Cr√©er un service Python avec Flask/FastAPI**

```python
# ml_service.py
from flask import Flask, request, jsonify
import tensorflow as tf
import numpy as np
from PIL import Image
import base64
import io

app = Flask(__name__)

# Charger le mod√®le
model = tf.keras.models.load_model('models/malaria_model.h5')

@app.route('/analyze', methods=['POST'])
def analyze():
    data = request.json
    image_base64 = data['image_base64']
    maladie_type = data['maladie_type']
    
    # D√©coder et preprocesser l'image
    image_data = base64.b64decode(image_base64)
    image = Image.open(io.BytesIO(image_data))
    processed = preprocess_image(image, maladie_type)
    
    # Faire la pr√©diction
    prediction = model.predict(processed)
    
    # Retourner les r√©sultats
    return jsonify({
        'detected': prediction[0] > 0.5,
        'confidence': float(prediction[0] * 100),
        'parasites_count': float(prediction[1]),
        'analysis_type': maladie_type,
    })

if __name__ == '__main__':
    app.run(port=5000)
```

2. **Modifier le backend Node.js pour appeler le service Python**

```javascript
// Dans ml_service.js
const axios = require('axios');

async analyzeImage(base64Image, maladieType) {
  try {
    const response = await axios.post('http://localhost:5000/analyze', {
      image_base64: base64Image,
      maladie_type: maladieType,
    });
    
    return response.data;
  } catch (error) {
    throw new Error(`Erreur ML Service: ${error.message}`);
  }
}
```

### Option 3 : API Cloud (Google Vision, AWS Rekognition)

```javascript
// Exemple avec Google Cloud Vision API
const vision = require('@google-cloud/vision');
const client = new vision.ImageAnnotatorClient();

async analyzeImage(base64Image, maladieType) {
  const image = {
    content: Buffer.from(base64Image, 'base64'),
  };
  
  // Utiliser l'API de d√©tection d'objets
  const [result] = await client.objectLocalization(image);
  // Adapter selon vos besoins de diagnostic
  
  return interpretVisionAPI(result);
}
```

## üì¶ D√©pendances ajout√©es

### Backend
- `bcrypt` : Hashage s√©curis√© des mots de passe
- `jsonwebtoken` : Tokens JWT pour l'authentification
- `@tensorflow/tfjs-node` : TensorFlow.js pour Node.js
- `sharp` : Traitement d'images performant

### Flutter
- `tflite_flutter` : TensorFlow Lite pour analyse offline (optionnel)

## üîí Authentification s√©curis√©e

L'authentification utilise maintenant :
- **Bcrypt** : Hashage des mots de passe (salt rounds: 10)
- **JWT** : Tokens d'authentification (expiration: 24h)

### Utilisation dans l'API

```javascript
// Prot√©ger une route
const { authenticateToken } = require('../middleware/auth');

router.get('/protected', authenticateToken, (req, res) => {
  // req.user contient les informations de l'utilisateur authentifi√©
  res.json({ user: req.user });
});
```

## üéØ Prochaines √©tapes

1. **Obtenir ou entra√Æner un mod√®le ML**
   - Mod√®le pour paludisme
   - Mod√®le pour typho√Øde
   - Validation avec dataset m√©dical r√©el

2. **Int√©grer le mod√®le**
   - Suivre l'une des options ci-dessus
   - Tester avec des images r√©elles
   - Ajuster le preprocessing si n√©cessaire

3. **Optimiser les performances**
   - Cache des r√©sultats
   - Queue pour les analyses longues
   - Optimisation du mod√®le

4. **Validation m√©dicale**
   - Tests avec professionnels de sant√©
   - Comparaison avec diagnostics r√©els
   - Ajustements selon les retours

## ‚ö†Ô∏è Notes importantes

- Le service ML actuel utilise une analyse basique (temporaire)
- Pour la production, int√©grer un vrai mod√®le entra√Æn√©
- Valider m√©dicalement avant d√©ploiement
- Respecter les r√©glementations m√©dicales locales

